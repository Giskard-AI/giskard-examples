{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pvKxJjsNSoE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![giskard_logo.png](https://raw.githubusercontent.com/Giskard-AI/giskard/main/readme/Logo_full_darkgreen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a9b17467105f4031a3f9eae70ef4138f",
    "deepnote_cell_height": 134,
    "deepnote_cell_type": "markdown",
    "id": "PKcOi3D37xbW",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# About Giskard\n",
    "\n",
    "Open-Source CI/CD platform for ML teams. Deliver ML products, better & faster. \n",
    "\n",
    "*   Collaborate faster with feedback from business stakeholders.\n",
    "*   Deploy automated tests to eliminate regressions, errors & biases.\n",
    "\n",
    "ğŸ¡ [Website](https://giskard.ai/)\n",
    "\n",
    "ğŸ“— [Documentation](https://docs.giskard.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f35c8e8d3fbf4c0f9c01a69673c318a1",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 6
    },
    "deepnote_cell_height": 110,
    "deepnote_cell_type": "markdown",
    "id": "mJTqM-W_7xbW",
    "owner_user_id": "41ec0844-b5b7-49c2-9460-710a452f98de",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Telco custormer churn data\n",
    "\n",
    "\n",
    "In this notebook we explore how to predict customer churn, a critical factor for telecommunication companies to be able to effectively retain customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing `giskard` and `lightgbm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting giskard\n",
      "  Downloading giskard-1.7.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightgbm\n",
      "  Downloading lightgbm-3.3.4-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting eli5<0.14.0,>=0.13.0\n",
      "  Downloading eli5-0.13.0.tar.gz (216 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.2/216.2 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting grpcio-status<2.0.0,>=1.46.3\n",
      "  Downloading grpcio_status-1.51.1-py3-none-any.whl (5.1 kB)\n",
      "Collecting importlib_metadata<5.0.0,>=4.11.4\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from giskard) (2.28.1)\n",
      "Collecting grpcio<2.0.0,>=1.46.3\n",
      "  Downloading grpcio-1.51.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm<5.0.0,>=4.64.1\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lockfile<0.13.0,>=0.12.2\n",
      "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting pandas<2.0.0,>=1.3.5\n",
      "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<2.0.0,>=1.10.2\n",
      "  Downloading pydantic-1.10.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil<6.0.0,>=5.9.2 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from giskard) (5.9.4)\n",
      "Collecting numpy<1.22.0,>=1.21.6\n",
      "  Downloading numpy-1.21.6-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-daemon<3.0.0,>=2.3.1\n",
      "  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)\n",
      "Collecting scipy<1.8,>=1.7.2\n",
      "  Downloading scipy-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting zstandard<0.16.0,>=0.15.2\n",
      "  Downloading zstandard-0.15.2-cp38-cp38-manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools<66.0.0,>=65.4.1 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from giskard) (65.6.3)\n",
      "Collecting protobuf<4.0.0,>=3.9.2\n",
      "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle<3.0.0,>=2.1.0\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting requests-toolbelt<0.10.0,>=0.9.1\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ipython<8.0.0,>=7.0.0\n",
      "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.11.1 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from giskard) (4.11.1)\n",
      "Collecting scikit-learn<1.1.0,>=1.0.0\n",
      "  Downloading scikit_learn-1.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting click<9.0.0,>=8.1.3\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting shap<0.42.0,>=0.41.0\n",
      "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m575.9/575.9 kB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mixpanel<5.0.0,>=4.10.0\n",
      "  Downloading mixpanel-4.10.0-py2.py3-none-any.whl (8.9 kB)\n",
      "Requirement already satisfied: wheel in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from lightgbm) (0.38.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from beautifulsoup4<5.0.0,>=4.11.1->giskard) (2.3.2.post1)\n",
      "Requirement already satisfied: attrs>17.1.0 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from eli5<0.14.0,>=0.13.0->giskard) (22.2.0)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from eli5<0.14.0,>=0.13.0->giskard) (3.1.2)\n",
      "Requirement already satisfied: six in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from eli5<0.14.0,>=0.13.0->giskard) (1.16.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.46.3\n",
      "  Downloading grpcio_status-1.50.0-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.49.1-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
      "Collecting googleapis-common-protos>=1.5.5\n",
      "  Downloading googleapis_common_protos-1.58.0-py2.py3-none-any.whl (223 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m223.0/223.0 kB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from importlib_metadata<5.0.0,>=4.11.4->giskard) (3.11.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from ipython<8.0.0,>=7.0.0->giskard) (5.8.1)\n",
      "Requirement already satisfied: pickleshare in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from ipython<8.0.0,>=7.0.0->giskard) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from ipython<8.0.0,>=7.0.0->giskard) (3.0.36)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from ipython<8.0.0,>=7.0.0->giskard) (0.18.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from ipython<8.0.0,>=7.0.0->giskard) (4.8.0)\n",
      "Requirement already satisfied: decorator in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from ipython<8.0.0,>=7.0.0->giskard) (5.1.1)\n",
      "Requirement already satisfied: backcall in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from ipython<8.0.0,>=7.0.0->giskard) (0.2.0)\n",
      "Requirement already satisfied: pygments in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from ipython<8.0.0,>=7.0.0->giskard) (2.14.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from ipython<8.0.0,>=7.0.0->giskard) (0.1.6)\n",
      "Requirement already satisfied: urllib3 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from mixpanel<5.0.0,>=4.10.0->giskard) (1.26.13)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.5->giskard) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from pydantic<2.0.0,>=1.10.2->giskard) (4.4.0)\n",
      "Requirement already satisfied: docutils in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from python-daemon<3.0.0,>=2.3.1->giskard) (0.19)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from requests<3.0.0,>=2.28.1->giskard) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from requests<3.0.0,>=2.28.1->giskard) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from requests<3.0.0,>=2.28.1->giskard) (2.1.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numba\n",
      "  Downloading numba-0.56.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>20.9 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from shap<0.42.0,>=0.41.0->giskard) (23.0)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from jedi>=0.16->ipython<8.0.0,>=7.0.0->giskard) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from jinja2>=3.0.0->eli5<0.14.0,>=0.13.0->giskard) (2.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from pexpect>4.3->ipython<8.0.0,>=7.0.0->giskard) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/gitpod/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.0.0->giskard) (0.2.5)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: eli5\n",
      "  Building wheel for eli5 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for eli5: filename=eli5-0.13.0-py2.py3-none-any.whl size=107729 sha256=b6b247ffe6e1e79b3f85ca68aabf6c9b4fc98f3d1bbd6769cef0d317fcd47db3\n",
      "  Stored in directory: /workspace/.pyenv_mirror/pip_cache/wheels/d0/b5/e0/9c5121f34043df6cbbec39ad10a5f059b75c883bce62a11379\n",
      "Successfully built eli5\n",
      "Installing collected packages: pytz, lockfile, zstandard, tqdm, threadpoolctl, tenacity, tabulate, slicer, python-daemon, pydantic, protobuf, numpy, llvmlite, joblib, importlib_metadata, grpcio, graphviz, cloudpickle, click, scipy, requests-toolbelt, pandas, numba, mixpanel, ipython, googleapis-common-protos, scikit-learn, grpcio-status, shap, lightgbm, eli5, giskard\n",
      "  Attempting uninstall: importlib_metadata\n",
      "    Found existing installation: importlib-metadata 6.0.0\n",
      "    Uninstalling importlib-metadata-6.0.0:\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\n",
      "  Attempting uninstall: requests-toolbelt\n",
      "    Found existing installation: requests-toolbelt 0.10.1\n",
      "    Uninstalling requests-toolbelt-0.10.1:\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.8.0\n",
      "    Uninstalling ipython-8.8.0:\n",
      "      Successfully uninstalled ipython-8.8.0\n",
      "Successfully installed click-8.1.3 cloudpickle-2.2.1 eli5-0.13.0 giskard-1.7.0 googleapis-common-protos-1.58.0 graphviz-0.20.1 grpcio-1.51.1 grpcio-status-1.48.2 importlib_metadata-4.13.0 ipython-7.34.0 joblib-1.2.0 lightgbm-3.3.4 llvmlite-0.39.1 lockfile-0.12.2 mixpanel-4.10.0 numba-0.56.4 numpy-1.21.6 pandas-1.5.3 protobuf-3.20.3 pydantic-1.10.4 python-daemon-2.3.2 pytz-2022.7.1 requests-toolbelt-0.9.1 scikit-learn-1.0.2 scipy-1.7.3 shap-0.41.0 slicer-0.0.7 tabulate-0.9.0 tenacity-8.1.0 threadpoolctl-3.1.0 tqdm-4.64.1 zstandard-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install giskard lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the external worker in daemon mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 08:42:07,325 pid:2887 MainThread giskard.cli  INFO     Starting ML Worker client daemon\n",
      "2023-01-20 08:42:07,325 pid:2887 MainThread giskard.cli  INFO     Python: /home/gitpod/.pyenv/versions/3.8.16/bin/python3 (3.8.16)\n",
      "2023-01-20 08:42:07,325 pid:2887 MainThread giskard.cli  INFO     Giskard Home: /home/gitpod/giskard-home\n",
      "2023-01-20 08:42:07,326 pid:2887 MainThread giskard.cli_utils INFO     Writing logs to /home/gitpod/giskard-home/run/ml-worker.log\n"
     ]
    }
   ],
   "source": [
    "!giskard worker start -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e8d609f32d5243dd917cc3104599b8d8",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 12
    },
    "deepnote_cell_height": 230,
    "deepnote_cell_type": "markdown",
    "id": "WNI85koE7xbX",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 1. Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lbt\n",
    "\n",
    "random_seed=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import telecom dataset into a pandas data frame\n",
    "\n",
    "dataset_url=\"https://raw.githubusercontent.com/Giskard-AI/examples/main/datasets/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "\n",
    "df_telco=pd.read_csv(dataset_url)\n",
    "\n",
    "# check unique values of each column\n",
    "#for column in df_telco.columns:\n",
    "#    print('Column: {} - Unique Values: {}'.format(column, df_telco[column].unique()))\n",
    "\n",
    "# summary of the data frame\n",
    "#df_telco.info()\n",
    "\n",
    "# transform the column TotalCharges into a numeric data type\n",
    "df_telco['TotalCharges'] = pd.to_numeric(df_telco['TotalCharges'], errors='coerce')\n",
    "\n",
    "# drop observations with null values\n",
    "df_telco.dropna(inplace=True)\n",
    "\n",
    "# drop the customerID column from the dataset\n",
    "df_telco.drop(columns='customerID', inplace=True)\n",
    "\n",
    "# remove (automatic) from payment method names\n",
    "df_telco['PaymentMethod'] = df_telco['PaymentMethod'].str.replace(' (automatic)', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialising feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the type of each column in the dataset(example: category, numeric, text)\n",
    "column_types = {'gender': \"category\",\n",
    "                'SeniorCitizen': \"category\", \n",
    "                'Partner': \"category\", \n",
    "                'Dependents': \"category\", \n",
    "                'tenure': \"numeric\",\n",
    "                'PhoneService': \"category\", \n",
    "                'MultipleLines': \"category\", \n",
    "                'InternetService': \"category\", \n",
    "                'OnlineSecurity': \"category\",\n",
    "                'OnlineBackup': \"category\", \n",
    "                'DeviceProtection': \"category\", \n",
    "                'TechSupport': \"category\", \n",
    "                'StreamingTV': \"category\",\n",
    "                'StreamingMovies': \"category\", \n",
    "                'Contract': \"category\", \n",
    "                'PaperlessBilling': \"category\", \n",
    "                'PaymentMethod': \"category\",\n",
    "                'MonthlyCharges': \"numeric\", \n",
    "                'TotalCharges': \"numeric\", \n",
    "                'Churn': \"category\"}\n",
    "\n",
    "# feature_types is used to declare the features the model is trained on\n",
    "feature_types = {i:column_types[i] for i in column_types if i!='Churn'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "columns_to_scale = [key for key in feature_types.keys() if feature_types[key]==\"numeric\"]\n",
    "\n",
    "columns_to_encode = [key for key in feature_types.keys() if feature_types[key]==\"category\"]\n",
    "\n",
    "# Perform preprocessing of the columns with the above pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), columns_to_scale),\n",
    "      ('cat', OneHotEncoder(handle_unknown='ignore',drop='first'), columns_to_encode)\n",
    "          ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select independent variables\n",
    "X = df_telco.drop(columns='Churn')\n",
    "\n",
    "# select dependent variables\n",
    "y = df_telco.loc[:, 'Churn']\n",
    "\n",
    "# split the data in training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=random_seed, shuffle=True)\n",
    "# Prepare data to upload on Giskard\n",
    "train_data = pd.concat([X_train, Y_train], axis=1)\n",
    "test_data = pd.concat([X_test, Y_test ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipelines and Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: dummy_classifier, Accuracy: 0.70193401592719)\n",
      "Classifier: k_nearest_neighbors, Accuracy: 0.7406143344709898)\n",
      "Classifier: logistic_regression, Accuracy: 0.8071672354948806)\n",
      "Classifier: random_forest, Accuracy: 0.7872582480091013)\n",
      "Classifier: gradient_boosting, Accuracy: 0.7963594994311718)\n",
      "Classifier: LGBM, Accuracy: 0.7963594994311718)\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "models['dummy_classifier']= {\"model\": DummyClassifier(random_state=random_seed, strategy='most_frequent'), \"accuracy\":0} \n",
    "models['k_nearest_neighbors']= {\"model\": KNeighborsClassifier(), \"accuracy\":0} \n",
    "models['logistic_regression']= {\"model\": LogisticRegression(random_state=random_seed,max_iter=150), \"accuracy\":0} \n",
    "models['random_forest']= {\"model\": RandomForestClassifier(random_state=random_seed), \"accuracy\":0} \n",
    "models['gradient_boosting']= {\"model\": GradientBoostingClassifier(random_state=random_seed), \"accuracy\":0} \n",
    "models['LGBM']= {\"model\": lbt.LGBMClassifier(random_state=random_seed), \"accuracy\":0} \n",
    "    \n",
    "\n",
    "# test the accuracy of each model using default hyperparameters\n",
    "scoring = 'accuracy'\n",
    "for name in models.keys():\n",
    "    models[name]['model']= Pipeline(steps=[('preprocessor', preprocessor), ('classifier', models[name]['model'])])\n",
    "    \n",
    "    # fit the model with the training data\n",
    "    models[name]['model'].fit(X_train, Y_train).predict(X_test)\n",
    "    # make predictions with the testing data\n",
    "    predictions = models[name]['model'].predict(X_test)\n",
    "    # calculate accuracy \n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    # append the model name and the accuracy to the lists\n",
    "    models[name]['accuracy']=accuracy\n",
    "    # print classifier accuracy\n",
    "    print('Classifier: {}, Accuracy: {})'.format(name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Upload the models in Giskard ğŸš€ğŸš€ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initiate a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from giskard import GiskardClient\n",
    "\n",
    "url = \"http://localhost:19000\" #if Giskard is installed locally (for installation, see: https://docs.giskard.ai/start/guides/installation)\n",
    "#url = \"http://app.giskard.ai\" # If you want to upload on giskard URL\n",
    "token = \"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJhZG1pbiIsInRva2VuX3R5cGUiOiJBUEkiLCJhdXRoIjoiUk9MRV9BRE1JTiIsImV4cCI6MTY4MTk4MDE3OX0.rVcLrpsKU5cE9ruLQKZsAzPlWdqMzHMpX8_-Pvi-7ak\"\n",
    "client = GiskardClient(url, token)\n",
    "\n",
    "# your_project = client.create_project(\"project_key\", \"PROJECT_NAME\", \"DESCRIPTION\")\n",
    "# Choose the arguments you want. But \"project_key\" should be unique and in lower case\n",
    "churn_analysis_with_tfs = client.create_project(\"churn_analysis_with_tfs\", \"Telco Kaggle Churn Analysis\", \"Project to predict if a customer quits\")\n",
    "\n",
    "# If you've already created a project with the key \"churn-analysis\" use\n",
    "#churn_analysis = client.get_project(\"churn_analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Upload a specific model and a dataset (see [documentation](https://docs.giskard.ai/start/guides/upload-your-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully uploaded to project key 'churn_analysis_with_tfs' with ID = 26. It is available at http://localhost:19000 \n",
      "Model successfully uploaded to project key 'churn_analysis_with_tfs' with ID = 27. It is available at http://localhost:19000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(27, 26)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_analysis_with_tfs.upload_model_and_df(\n",
    "    prediction_function=models['dummy_classifier']['model'].predict_proba, # Python function which takes pandas dataframe as input and returns probabilities for classification model OR returns predictions for regression model\n",
    "    model_type='classification', # \"classification\" for classification model OR \"regression\" for regression model\n",
    "    df=test_data, # the dataset you want to use to inspect your model\n",
    "    column_types=column_types, # A dictionary with columns names of df as key and types(category, numeric, text) of columns as values\n",
    "    target='Churn', # The column name in df corresponding to the actual target variable (ground truth).\n",
    "    feature_names=list(feature_types.keys()), # List of the feature names of prediction_function\n",
    "    classification_labels=[\"No\",\"Yes\"] ,  # List of the classification labels of your prediction #TODO: Check their order!!!!!\n",
    "    model_name='dummy_classifier', # Name of the model\n",
    "    dataset_name='test_data' # Name of the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload more models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in models.keys():\n",
    "    if name=='dummy_classifier': continue\n",
    "    churn_analysis_with_tfs.upload_model(\n",
    "        prediction_function=models[name]['model'].predict_proba, # Python function which takes pandas dataframe as input and returns probabilities for classification model OR returns predictions for regression model\n",
    "        model_type='classification', # \"classification\" for classification model OR \"regression\" for regression model\n",
    "        feature_names=list(feature_types.keys()), # List of the feature names of prediction_function\n",
    "        name=name, # Name of the model\n",
    "        target=\"Churn\", # Optional. target sshould be a column of validate_df. Pass this parameter only if validate_df is being passed\n",
    "        classification_labels=[\"No\",\"Yes\"] # List of the classification labels of your prediction\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload more datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_analysis_with_tfs.upload_df(\n",
    "    df=train_data, # The dataset you want to upload\n",
    "    column_types=column_types, # All the column types of df\n",
    "    target=\"Churn\", # Do not pass this parameter if dataset doesn't contain target column\n",
    "    name=\"train_data\" # Name of the dataset\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "German_credit_scoring_giskard (2).ipynb",
   "provenance": []
  },
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6e7ea85d-f19e-4d05-90a4-44b7668fd037",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
